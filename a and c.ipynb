{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense,Conv2D,Flatten,Dropout,MaxPool2D\n",
    "from keras.preprocessing.image import image,load_img,img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = image.list_pictures(\"train/\")\n",
    "test = image.list_pictures(\"test/\")\n",
    "#instatiate the test and train images\n",
    "d1 = np.zeros([len(train),32,32,3])\n",
    "d2 = np.zeros([len(test),32,32,3])\n",
    "def convert_to_numpy(file,list):\n",
    "    i = 0\n",
    "    for im in file:\n",
    "        #read the image\n",
    "        try:\n",
    "            z = load_img(im)\n",
    "            #convert into images and replace in the instatiated datasets above\n",
    "            list[i] = img_to_array(z)\n",
    "            i += 1\n",
    "            if (i%500==0):\n",
    "                print(\"{} images converted\".format(i))\n",
    "        except:\n",
    "            print(\"Cannot process image {}\".format(im))\n",
    "            break\n",
    "    print (\"Conversion is Completed\")\n",
    "\n",
    "print(\"Training Set\")\n",
    "convert_to_numpy(train,d1)\n",
    "print(\"Testing Set\")\n",
    "convert_to_numpy(test,d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the data\n",
    "d1 = (d1 -128)/ 128\n",
    "d2 = (d2-128)/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def refactor(dt,list)\n",
    "    img_id = []\n",
    "    for dir in list:\n",
    "        img_id.append(dir.split(\"/\")[1])\n",
    "    img_id_df = pd.Series(img_id,name='id')\n",
    "\n",
    "\n",
    "    #reshape your image and join\n",
    "    dt1 = dt.reshape([dt.shape[0],32*32*3])\n",
    "    dt_df = pd.DataFrame(dt1)\n",
    "\n",
    "    del dt1\n",
    "    del img_id\n",
    "\n",
    "    #joining the dataframe together \n",
    "    d = dt_df.join(img_id_df)\n",
    "\n",
    "    del dt_df\n",
    "    del img_id_df\n",
    "    gc.collect()\n",
    "    return d\n",
    "#dt = refactor(d1,train)\n",
    "#dt2 = refactor(d2,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#merge the two datasets for proper labeling\n",
    "#final_train_df = dt.merge(train_df,on=\"id\")\n",
    "#final_train_df.to_csv(\"traindata.csv\",index=False)\n",
    "\n",
    "#final_test_df = dt2.merge(test_df,on=\"id\")\n",
    "#final_test_df.to_csv(\"testdata.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17500, 32, 32, 3)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in the data\n",
    "#start from here next time\n",
    "\n",
    "final_train_df = pd.to_csv(\"traindata.csv\",index=False)\n",
    "\n",
    "#final_test_df = dt2.merge(test_df,on=\"id\")\n",
    "#final_test_df.to_csv(\"testdata.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_train_df = pd.read_csv(\"traindata.csv\")\n",
    "\n",
    "#X = final_train_df.drop(['has_cactus','id'],axis=1)\n",
    "#y = final_train_df['has_cactus']\n",
    "\n",
    "Xtest = final_test_df.drop(['has_cactus','id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "\n",
    "#X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12292000"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4000*3073"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting back to numpy and reshaping\n",
    "#Xtrain = X.values.reshape([len(X),32,32,3])\n",
    "#ytrain = y.values\n",
    "\n",
    "Xtest = Xtest.values.reshape([len(Xtest),32,32,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating your model\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(8,(5,5),activation=\"relu\",input_shape=(32,32,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\"adam\",loss=\"mse\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "17500/17500 [==============================] - 49s 3ms/step - loss: 0.0452 - acc: 0.9408\n",
      "Epoch 2/15\n",
      "17500/17500 [==============================] - 11s 617us/step - loss: 0.0258 - acc: 0.9674\n",
      "Epoch 3/15\n",
      "17500/17500 [==============================] - 11s 621us/step - loss: 0.0214 - acc: 0.9722\n",
      "Epoch 4/15\n",
      "17500/17500 [==============================] - 11s 636us/step - loss: 0.0165 - acc: 0.9791\n",
      "Epoch 5/15\n",
      "17500/17500 [==============================] - 11s 655us/step - loss: 0.0153 - acc: 0.98050s - loss: 0.0154 - acc: 0 - ETA: 0s - loss: 0.0154 - \n",
      "Epoch 6/15\n",
      "17500/17500 [==============================] - 11s 642us/step - loss: 0.0139 - acc: 0.9825\n",
      "Epoch 7/15\n",
      "17500/17500 [==============================] - 11s 657us/step - loss: 0.0100 - acc: 0.9874\n",
      "Epoch 8/15\n",
      "17500/17500 [==============================] - 12s 675us/step - loss: 0.0100 - acc: 0.9872\n",
      "Epoch 9/15\n",
      "17500/17500 [==============================] - 12s 699us/step - loss: 0.0080 - acc: 0.99021s - loss: \n",
      "Epoch 10/15\n",
      "17500/17500 [==============================] - 11s 644us/step - loss: 0.0062 - acc: 0.9924\n",
      "Epoch 11/15\n",
      "17500/17500 [==============================] - 12s 714us/step - loss: 0.0064 - acc: 0.9921\n",
      "Epoch 12/15\n",
      "17500/17500 [==============================] - 11s 629us/step - loss: 0.0058 - acc: 0.9927\n",
      "Epoch 13/15\n",
      "17500/17500 [==============================] - 11s 644us/step - loss: 0.0054 - acc: 0.9933\n",
      "Epoch 14/15\n",
      "17500/17500 [==============================] - 11s 627us/step - loss: 0.0043 - acc: 0.9951\n",
      "Epoch 15/15\n",
      "17500/17500 [==============================] - 11s 635us/step - loss: 0.0057 - acc: 0.9933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f441ed2d30>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain,ytrain,batch_size=32,epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pred.round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df['has_cactus'] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.to_csv(\"submit.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
